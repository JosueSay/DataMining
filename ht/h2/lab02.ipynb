{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Clustering - Conjunto de Datos Iris\n",
        "\n",
        "Aplicando técnicas de clustering se buscó segmentar las especies de la flor Iris utilizando el conjunto de datos clásico de Machine Learning. Se explorarán los datos visualmente y se implementará el algoritmo K-Means para agrupar las muestras según la forma del sépalo y el pétalo. Además, se empleará el método del \"codo\" y la librería kneed para determinar el número óptimo de clusters. Finalmente, se compararán los resultados obtenidos con los datos reales para evaluar la efectividad del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.cluster.hierarchy as sch\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import plotly.express as px\n",
        "from sklearn.cluster import KMeans\n",
        "from kneed import KneeLocator\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def borrarNulosDuplicados(df, cant_object, cant_obs, flag_object):\n",
        "    if cant_obs == 0:  \n",
        "        print(\"No hay observaciones en el DataFrame.\")\n",
        "        return df\n",
        "    \n",
        "    prop = cant_object / cant_obs\n",
        "    type_data = \"nulos\" if flag_object else \"duplicados\"\n",
        "\n",
        "    if prop == 0:\n",
        "        print(f\"El porcentaje de datos {type_data} es del 0%. No es necesario eliminarlos.\")\n",
        "    elif prop > 0.05:  # Regla del 5%\n",
        "        print(f\"El porcentaje de datos {type_data} es del {prop*100:.2f}%. Se debe hacer otro método de eliminación.\")\n",
        "    else:\n",
        "        print(f\"El porcentaje de datos {type_data} es del {prop*100:.2f}%. Se pueden eliminar los datos.\")\n",
        "\n",
        "        if flag_object:\n",
        "            df = df.dropna()\n",
        "        else:\n",
        "            df = df.drop_duplicates()\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "iris_df_s1 = pd.read_csv(\"iris.csv\")\n",
        "\n",
        "columns = iris_df_s1.columns\n",
        "cant_obs = iris_df_s1.shape[0]\n",
        "cant_var = iris_df_s1.shape[1]\n",
        "cant_nulos = iris_df_s1.isnull().sum().sum()\n",
        "cant_dupli = iris_df_s1.duplicated().sum()\n",
        "\n",
        "print(\"- Vista Previa DF:\\n\",iris_df_s1.head(10))\n",
        "print(f\"- Tamaño de DF: \\n\\t• {cant_obs} filas \\n\\t• {cant_var} columnas\")\n",
        "print(f\"- Existen: \\n\\t• {cant_nulos} valores nulos \\n\\t• {cant_dupli} valores duplicados\")\n",
        "print(\"- Columnas:\")\n",
        "for col in columns:\n",
        "  print(f\"\\t• {col}\")\n",
        "\n",
        "\n",
        "iris_df_s1 = borrarNulosDuplicados(df=iris_df_s1, cant_object=cant_nulos, cant_obs=cant_obs, flag_object=True)\n",
        "iris_df_s1 = borrarNulosDuplicados(df=iris_df_s1, cant_object=cant_dupli, cant_obs=cant_obs, flag_object=False)\n",
        "iris_df_s2 = iris_df_s1.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sección 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Visualicen los datos para ver si pueden detectar algunos grupos. Ayuda: utilicen la forma del sépalo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gráfico de dispersión de la forma del sépalo\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.scatter(iris_df_s1[\"sepal_length\"], iris_df_s1[\"sepal_width\"], alpha=0.6)\n",
        "\n",
        "# Etiquetas\n",
        "plt.xlabel(\"Longitud del Sépalo\")\n",
        "plt.ylabel(\"Ancho del Sépalo\")\n",
        "plt.title(\"Visualización de Datos: Sépalo\")\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Respuesta:**\n",
        "\n",
        "A simple vista, podemos notar que hay ciertos grupos de puntos, lo que sugiere que los datos pueden agruparse en clusters. \n",
        "\n",
        "Sin embargo, los puntos aún no tienen etiquetas, por lo que necesitamos aplicar métodos de clustering para confirmar las agrupaciones. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Creen 2 \"clusters\" utilizando K_Means Clustering y grafiquen los resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "linked = sch.linkage(iris_df_s1[[\"sepal_length\", \"sepal_width\"]], method = \"ward\")\n",
        "plt.figure(figsize=(10,5))\n",
        "sch.dendrogram(linked, no_labels = True, color_threshold = 4)\n",
        "\n",
        "# Etiquetas\n",
        "plt.xlabel(\"Dendograma del Clustering Jerárquico (Sépalo)\")\n",
        "plt.ylabel(\"Muestra de Datos\")\n",
        "plt.title(\"Distancia\")\n",
        "\n",
        "# Mostrar dendograma\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Respuesta:**\n",
        "\n",
        "El dendrograma nos permite visualizar cómo se agrupan los datos jerárquicamente.\n",
        "\n",
        "Cada bifurcación representa la unión de dos clusters.\n",
        "\n",
        "El número de cortes óptimo en el dendrograma sugiere cuántos clusters podrían ser adecuados para los datos.\n",
        "\n",
        "En este caso, parece haber al menos 3 o 4 posibles agrupaciones (separadas por diferentes colores).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. **Creen 2 \"clusters\" utilizando K_Means Clustering y grafiquen los resultados**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Aplicar K-Means con 2 clusters\n",
        "kmeans_2 = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "\n",
        "# Ajustar el modelo a los datos del sépalo\n",
        "iris_df_s1[\"cluster_2\"] = kmeans_2.fit_predict(iris_df_s1[['sepal_length', 'sepal_width']])\n",
        "\n",
        "# Graficar los clusters resultantes\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=iris_df_s1[\"sepal_length\"], y=iris_df_s1[\"sepal_width\"], hue=iris_df_s1[\"cluster_2\"], palette=\"viridis\")\n",
        "\n",
        "# Marcar los centroides\n",
        "centroids = kmeans_2.cluster_centers_\n",
        "plt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='X', s=200, label=\"Centroides\")\n",
        "\n",
        "# Etiquetas\n",
        "plt.xlabel(\"Longitud del Sépalo\")\n",
        "plt.ylabel(\"Ancho del Sépalo\")\n",
        "plt.title(\"K-Means con 2 Clusters (Forma del Sépalo)\")\n",
        "plt.legend()\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Respuesta:**\n",
        "\n",
        "Se ven dos grupos, el azul y el verde\n",
        "\n",
        "Las X rojas en el gráfico muestran los puntos donde K-Means considera que están los centros de los grupos.\n",
        "\n",
        "El conjunto de datos de Iris contiene 3 especies reales, pero en este análisis hemos forzado a K-Means a identificar solo 2 clusters, lo que puede provocar una segmentación incorrecta de algunas flores. Como resultado, algunos datos que deberían pertenecer a un tercer grupo han sido asignados erróneamente a uno de los dos clusters existentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. **Estandaricen los datos e intenten el paso 2, de nuevo. ¿Qué diferencias hay, si es que lo hay?**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Estandarizar los datos del sépalo\n",
        "scaler = StandardScaler()\n",
        "iris_df_s1[['sepal_length', 'sepal_width']] = scaler.fit_transform(iris_df_s1[['sepal_length', 'sepal_width']])\n",
        "\n",
        "# Aplicar K-Means nuevamente con los datos estandarizados\n",
        "kmeans_2_std = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
        "iris_df_s1[\"cluster_2_std\"] = kmeans_2_std.fit_predict(iris_df_s1[['sepal_length', 'sepal_width']])\n",
        "\n",
        "# Graficar los clusters después de la estandarización\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.scatterplot(x=iris_df_s1[\"sepal_length\"], y=iris_df_s1[\"sepal_width\"], hue=iris_df_s1[\"cluster_2_std\"], palette=\"viridis\")\n",
        "\n",
        "# Marcar los centroides después de la estandarización\n",
        "centroids_std = kmeans_2_std.cluster_centers_\n",
        "plt.scatter(centroids_std[:, 0], centroids_std[:, 1], c='red', marker='X', s=200, label=\"Centroides\")\n",
        "\n",
        "# Etiquetas\n",
        "plt.xlabel(\"Longitud del Sépalo (Estandarizado)\")\n",
        "plt.ylabel(\"Ancho del Sépalo (Estandarizado)\")\n",
        "plt.title(\"K-Means con 2 Clusters (Datos Estandarizados)\")\n",
        "plt.legend()\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Respuesta:**\n",
        "\n",
        "Los valores ahora están en una escala normalizada, los centroides se ajustaron a la nueva escala, la separación de clusters ahora es más equitativa, en el anterior se ve como favorece más a la variable con mayor rango (sepal_length). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Utilicen el método del \"codo\" para determinar cuantos \"clusters\" es el ideal. (prueben un rango de 1 a 10)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inercia_clusters = []  # Lista para almacenar la inercia (within-cluster sum of squares)\n",
        "k_range = range(1, 11)\n",
        "\n",
        "# Calcular WCSS para cada número de clusters\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(iris_df_s1[['sepal_length', 'sepal_width']])  # Usamos datos estandarizados\n",
        "    inercia_clusters.append(kmeans.inertia_)  # Guardamos la inercia\n",
        "\n",
        "# Graficar el método del codo\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(k_range, inercia_clusters, marker='o', linestyle='--')\n",
        "\n",
        "# Etiquetas\n",
        "plt.xlabel(\"Número de Clusters (k)\")\n",
        "plt.ylabel(\"WCSS (Suma de Cuadrados Intra-cluster)\")\n",
        "plt.title(\"Método del Codo para Determinar k Óptimo\")\n",
        "\n",
        "# Mostrar el gráfico\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Respuesta:**\n",
        "\n",
        "**El gráfico muestra una curva decreciente:**\n",
        "\n",
        "Parece que el cambio de pendiente más notorio ocurre en k=3 o k=4;\n",
        "Después de k=4, la reducción de WCSS es mucho más lenta, esto sugiere que 3 o 4 clusters son la mejor elección."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Basado en la gráfica del \"codo\" realicen varias gráficas con el número de clusters (unos 3 o 4 diferentes) que Uds creen mejor se ajusten a los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Aplicar K-Means con diferentes números de clusters (3, 4, 5 y 6)\n",
        "k_values = [3, 4, 5, 6]  # Diferentes cantidades de clusters a probar\n",
        "\n",
        "# Crear subgráficos para visualizar los resultados\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "for i, k in enumerate(k_values):\n",
        "    # Entrenar K-Means con k clusters\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    iris_df_s1[f'cluster_{k}'] = kmeans.fit_predict(iris_df_s1[['sepal_length', 'sepal_width']])\n",
        "\n",
        "    # Seleccionar el eje correspondiente\n",
        "    ax = axes[i // 2, i % 2]\n",
        "    \n",
        "    # Graficar los clusters resultantes\n",
        "    sns.scatterplot(x=iris_df_s1[\"sepal_length\"], y=iris_df_s1[\"sepal_width\"],\n",
        "                    hue=iris_df_s1[f'cluster_{k}'], palette=\"viridis\", ax=ax)\n",
        "\n",
        "    # Marcar los centroides\n",
        "    centroids = kmeans.cluster_centers_\n",
        "    ax.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='X', s=200, label=\"Centroides\")\n",
        "\n",
        "    # Etiquetas\n",
        "    ax.set_xlabel(\"Longitud del Sépalo (Estandarizado)\")\n",
        "    ax.set_ylabel(\"Ancho del Sépalo (Estandarizado)\")\n",
        "    ax.set_title(f\"K-Means con {k} Clusters\")\n",
        "\n",
        "    ax.legend()\n",
        "\n",
        "# Ajustar espacio entre gráficos\n",
        "plt.tight_layout()\n",
        "\n",
        "# Mostrar los gráficos\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Respuesta:**\n",
        "\n",
        "**K-Means con 3 clusters:** Las agrupaciones parecen bastante naturales, sin embargo algunos puntos aún parecen bastantes naturales.\n",
        "**K-Means con 4 clusters:** Se observa una división más detallada dentro de los clusters, este resultado puede ser útil si queremos una separación más precisa de subgrupos.\n",
        "\n",
        "**K-Means con 5 clusters:** Aquí los clusters se empiezan a fragmentar demasiado, se puede notar grupos más pequeños que quizás no tengan una diferencia biológica real.\n",
        "\n",
        "**K-Means con 6 clusters:** Se observa una sobre-segmentación de demasiados clusters, algunas indican que quizá 6 clusters es demasiado.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Comparen sus soluciones con los datos reales, archivo: iris-con-respuestas.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Cargar el dataset nuevamente\n",
        "iris_df_s1 = pd.read_csv(\"iris.csv\")\n",
        "\n",
        "# Estandarizar los datos del sépalo\n",
        "scaler = StandardScaler()\n",
        "iris_scaled = scaler.fit_transform(iris_df_s1[['sepal_length', 'sepal_width']])\n",
        "\n",
        "# Aplicar K-Means con k=3 clusters\n",
        "kmeans_3 = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
        "iris_df_s1[\"cluster_3\"] = kmeans_3.fit_predict(iris_scaled)\n",
        "\n",
        "# Verificar que la columna 'cluster_3' existe\n",
        "print(iris_df_s1.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Cargar los datos reales con especies\n",
        "iris_real = pd.read_csv(\"iris-con-respuestas.csv\")\n",
        "\n",
        "# Unir los datos reales con los clusters obtenidos con K-Means\n",
        "iris_comparacion = iris_real.copy()\n",
        "iris_comparacion[\"cluster_3\"] = iris_df_s1[\"cluster_3\"]\n",
        "\n",
        "# Crear una tabla de contingencia para comparar clusters con especies reales\n",
        "tabla_comparacion = pd.crosstab(iris_comparacion[\"cluster_3\"], iris_comparacion[\"species\"])\n",
        "\n",
        "# Mostrar la tabla en texto\n",
        "print(\"Tabla de comparación entre Clusters y Especies Reales:\")\n",
        "print(tabla_comparacion)\n",
        "\n",
        "# Crear un gráfico de calor para visualizar la tabla de contingencia\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(tabla_comparacion, annot=True, cmap=\"viridis\", fmt=\"d\")\n",
        "plt.xlabel(\"Especie Real\")\n",
        "plt.ylabel(\"Cluster Asignado\")\n",
        "plt.title(\"Comparación Clusters vs Especies Reales\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Respuesta:**\n",
        "La especie Setosa fue perfectamente identificada, con 49 de 50 flores asignadas correctamente al mismo cluster, validando que K-Means detectó claramente este grupo. Sin embargo, Versicolor y Virginica no fueron bien separadas, ya que sus datos se distribuyeron en dos clusters sin una distinción clara. Esto indica que usar solo las variables sepal_length y sepal_width no es suficiente para diferenciar estas especies de manera efectiva. Basándonos en los pasos previos, donde confirmamos que k=3 era el número óptimo de clusters, podemos concluir que la metodología aplicada fue correcta, pero que la segmentación podría mejorarse incorporando petal_length y petal_width en el análisis para lograr una mejor clasificación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7. ¡Obviamente solo hay tres especies, porque ese es el archivo de datos reales!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ¿Funcionó el clustering con la forma del sépalo?\n",
        "\n",
        "**Respuesta:**\n",
        "\n",
        "Tras aplicar K-Means con k=3 usando únicamente la forma del sépalo (sepal_length y sepal_width), observamos que el modelo logró identificar claramente la especie Setosa, ya que sus características son más distintivas. Sin embargo, Versicolor y Virginica no fueron bien separadas, ya que estas especies presentan una mayor superposición en términos de sépalo.\n",
        "\n",
        "Si bien el método del codo confirmó que tres clusters eran adecuados, la tabla de comparación entre clusters y especies reales mostró que Versicolor y Virginica quedaron mezcladas en dos clusters distintos, lo que indica que la forma del sépalo no es suficiente para diferenciarlas correctamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sección 2\n",
        "\n",
        "Repitan el proceso pero ahora utilizando la forma del pétalo. Respondan a las mismas preguntas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Muestra inicial\n",
        "petals = iris_df_s2.filter(items=[\"petal_length\", \"petal_width\"])\n",
        "print(petals.head(n=10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Visualicen los datos para ver si pueden detectar algunos grupos. Ayuda: utilicen la forma del pétalo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Crear gráfico de dispersión\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(petals[\"petal_length\"], petals[\"petal_width\"], alpha=0.6)\n",
        "\n",
        "# Configurar etiquetas y título\n",
        "plt.xlabel(\"Petal Length\")\n",
        "plt.ylabel(\"Petal Width\")\n",
        "plt.title(\"Visualización de la Forma del Pétalo\")\n",
        "\n",
        "# Mostrar gráfico\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Respuesta:** Se observa una clara separación de grupos que corresponde a la proporción entre el largo y el ancho de los pétalos. Los pétalos con menor longitud tienden a tener un ancho pequeño, mientras que los pétalos más largos presentan un ancho proporcionalmente mayor. Esto sugiere la existencia de una relación lineal positiva entre ambas variables. Además, la separación de grupos podría indicar la presencia de categorías o especies diferentes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Creen 2 \"clusters\" utilizando K_Means Clustering y grafiquen los resultados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Función para aplicar el algoritmo K-Means y visualizar los clusters generados mediante una gráfica de dispersión.\n",
        "\n",
        "Parámetros:\n",
        "- df (DataFrame): Conjunto de datos sobre el cual se aplicará K-Means.\n",
        "- n (int): Número de clusters a generar.\n",
        "- flag (bool): Si es `True`, muestra mensajes y resultados intermedios dentro de la función.\n",
        "- getDF (bool): Si es `True`, retorna el DataFrame modificado con una nueva columna de clusters.\n",
        "\n",
        "Retorno:\n",
        "- DataFrame modificado con los clusters asignados (si `getDF=True`).\n",
        "- DataFrame con la cantidad de observaciones por cluster.\n",
        "\"\"\"\n",
        "def kMeansIrisPetalo(df, k, flag = False, getDF = False):\n",
        "  \n",
        "  kmeans = KMeans(n_clusters = k)\n",
        "  kmeans.fit(df)\n",
        "  clusters_identificados = kmeans.fit_predict(df)\n",
        "  \n",
        "  if flag:\n",
        "    print(clusters_identificados)\n",
        "\n",
        "  # Crear una copia de los datos\n",
        "  datos_con_clusters = df.copy()\n",
        "\n",
        "  # Crear una nueva serie, que tenga el cluster identificado para cada observación\n",
        "  datos_con_clusters['Cluster'] = clusters_identificados\n",
        "\n",
        "  if flag:\n",
        "    print(datos_con_clusters)\n",
        "\n",
        "  # Contar la cantidad de datos en cada cluster\n",
        "  cantidad_por_cluster = datos_con_clusters[\"Cluster\"].value_counts()\n",
        "  datos_con_clusters[\"Cluster\"] = datos_con_clusters[\"Cluster\"].astype(\"category\")\n",
        "\n",
        "  fig = px.scatter(datos_con_clusters, \n",
        "                  x = \"petal_length\", \n",
        "                  y = \"petal_width\", \n",
        "                  color = \"Cluster\",\n",
        "                  title= f\"Kmeans para {k} clústers\"\n",
        "                  )\n",
        "\n",
        "  fig.show()\n",
        "  \n",
        "  return (datos_con_clusters, cantidad_por_cluster) if getDF else cantidad_por_cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clusters_normal = kMeansIrisPetalo(df=petals, k=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Respuesta:** Se puede visualizar los clusters por colores:\n",
        "\n",
        "- `Cluster 0 (rojo)` representa una agrupación de puntos que están distribuidos principalmente en la región con valores más altos de petal_length y petal_width.\n",
        "- `Cluster 1 (azul)` representa puntos en la región con valores más bajos de petal_length y petal_width.\n",
        "\n",
        "La separación de clusters también refuerza la relación lineal positiva entre *petal_length* y *petal_width*, ya que los puntos de cada cluster están alineados siguiendo esa tendencia como se mencionó en el inciso 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Estandaricen los datos e intenten el paso 2, de nuevo. ¿Qué diferencias hay, si es que lo hay?."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Función para aplicar el escalamiento estándar a un conjunto de datos, transformando los valores a una distribución con media 0 y desviación estándar 1 (rango aproximado entre -3 y 3).\n",
        "\n",
        "Parámetros:\n",
        "- df (DataFrame): DataFrame con los datos a escalar.\n",
        "\n",
        "Retorno:\n",
        "- DataFrame escalado con media 0 y desviación estándar 1.\n",
        "\"\"\"\n",
        "def escalarDatos(df):\n",
        "  scaler = StandardScaler()\n",
        "  petals_standardized = scaler.fit_transform(df)\n",
        "  petals_scaled_df = pd.DataFrame(petals_standardized, columns=df.columns)\n",
        "  return petals_scaled_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Escalar datos y obtener aplicar K-means\n",
        "petals_scaled_df = escalarDatos(df=petals)\n",
        "clusters_estandar = kMeansIrisPetalo(df=petals_scaled_df, k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(clusters_normal)\n",
        "print(clusters_estandar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Respuesta:** Cuando estandarizamos los datos, le decimos al algoritmo de K-Means que no le dé más importancia a los números grandes que a los pequeños. Por ejemplo, en este caso, la longitud del pétalo (petal_length) y el ancho del pétalo (petal_width) están en centímetros:\n",
        "\n",
        "- Los cambios en X (longitud del pétalo) afectaban mucho más la distancia entre los puntos y los centros de los clusters que los cambios en Y (ancho del pétalo).\n",
        "- El punto que cambió de cluster probablemente estaba más cerca del centro del Cluster 0 en términos de petal_length, pero no tanto en petal_width."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Utilicen el método del \"codo\" para determinar cuantos \"clusters\" es el ideal. (prueben un rango de 1 a 10)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Función para aplicar el \"método del codo\" a un DataFrame, determinando de forma visual el número óptimo de clusters (k) en un rango especificado.\n",
        "\n",
        "La función utiliza el algoritmo K-Means con los siguientes parámetros:\n",
        "- Inicialización aleatoria (`init=\"random\"`).\n",
        "- Número de inicializaciones (`n_init=10`).\n",
        "- Iteraciones máximas (`max_iter=300`).\n",
        "- Semilla aleatoria (`random_state=42`) para reproducibilidad.\n",
        "\n",
        "Parámetros:\n",
        "- df (DataFrame): DataFrame sobre el cual se evaluará la cantidad adecuada de clusters.\n",
        "- i (int): Valor inicial del rango de clusters a evaluar.\n",
        "- f (int): Valor final del rango de clusters a evaluar.\n",
        "\n",
        "Retorno:\n",
        "- wcss (list): Lista de valores de WCSS (Within-Cluster Sum of Squares) para cada número \n",
        "               de clusters evaluado (dispersion de datos para cada cluster).\n",
        "\"\"\"\n",
        "def metodoCodo(df, i, f):\n",
        "    # Parámetros de K-Means\n",
        "    kmeans_kwargs = {\n",
        "        \"init\": \"random\",\n",
        "        \"n_init\": 10,\n",
        "        \"max_iter\": 300,\n",
        "        \"random_state\": 42,\n",
        "    }\n",
        "\n",
        "    # Lista para almacenar los valores de WCSS\n",
        "    wcss = []\n",
        "\n",
        "    # Iterar para diferentes valores de K (número de clusters)\n",
        "    for k in range(i, f+1):\n",
        "        kmeans = KMeans(n_clusters=k, **kmeans_kwargs)\n",
        "        kmeans.fit(df)\n",
        "        wcss.append(kmeans.inertia_)\n",
        "\n",
        "    # Crear un DataFrame para visualizar WCSS\n",
        "    datos_WCSS = pd.DataFrame({\"K\": range(i, f+1), \"WCSS\": wcss})\n",
        "\n",
        "    # Graficar la relación entre K y WCSS\n",
        "    fig = px.line(datos_WCSS, x=\"K\", y=\"WCSS\", title=\"Método del Codo: WCSS vs K\")\n",
        "    fig.update_xaxes(title_text=\"Número de Clusters (K)\")\n",
        "    fig.update_yaxes(title_text=\"WCSS\")\n",
        "    fig.show()\n",
        "    \n",
        "    return wcss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "wcss_pet = metodoCodo(df= petals_scaled_df, i=1, f=10)\n",
        "print(wcss_pet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Respuesta:** En la gráfica se observa que el descenso o cambio se reduce notablemente a partir de k = 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Basado en la gráfica del \"codo\" realicen varias gráficas con el número de clusters (unos 3 o 4 diferentes) que Uds creen mejor se ajusten a los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtener la cantidad de observacioines por cluster, para k = 3 obtener el dataframe modificado\n",
        "cluster_n2 = kMeansIrisPetalo(df=petals_scaled_df, k=2)\n",
        "iris_compare, cluster_n3 = kMeansIrisPetalo(df=petals_scaled_df, k=3, getDF=True)\n",
        "cluster_n4 = kMeansIrisPetalo(df=petals_scaled_df, k=4)\n",
        "cluster_n5 = kMeansIrisPetalo(df=petals_scaled_df, k=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Comparen sus soluciones con los datos reales, archivo: iris-con-respuestas.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparaciones por cantidad de datos por clusters y los valores de la respuestas\n",
        "iris_sol = pd.read_csv(\"iris-con-respuestas.csv\")\n",
        "iris_sol_species = iris_sol[\"species\"]\n",
        "iris_compare_cluster = iris_compare[\"Cluster\"]\n",
        "\n",
        "print(\"- Categorías de DF comparación:\\n\", iris_compare_cluster.unique(),\"\\n\")\n",
        "print(\"- Cantidad de cada categoría de DF comparación:\\n\", iris_compare_cluster.value_counts(),\"\\n\")\n",
        "print(\"- Categorías de DF solución:\\n\", iris_sol_species.unique(),\"\\n\")\n",
        "print(\"- Cantidad de cada categoría de DF solución:\\n\", iris_sol_species.value_counts(),\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tabla para determinar la relacion cluster - especie\n",
        "table_compare = pd.crosstab(iris_compare_cluster, iris_sol_species)\n",
        "print(\"- Tabla cruzada de clusters/species:\\n\")\n",
        "print(table_compare)\n",
        "\n",
        "print(\"\\n- Porcentaje de precisión de K-means:\\n\")\n",
        "\n",
        "# Presición de K-means por cluster según su relación cruzada en la tabla\n",
        "for i in range(len(table_compare.columns)):  \n",
        "    nCol = table_compare.columns[i]\n",
        "    col = table_compare[nCol]\n",
        "    cant_sol = col.sum()\n",
        "    cant_compare = col.max()\n",
        "    fila_max = col.idxmax()\n",
        "    presicion = (cant_compare * 100)/cant_sol\n",
        "    print(f\"\\tEl cluster {fila_max} tuvo una presición del {presicion:.1f}% correspondiente a la especie {nCol}.\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Respuesta:** El archivo iris-con-respuestas.csv tiene las especies reales de las flores: setosa, versicolor y virginica. Cada especie tiene exactamente 50 observaciones, lo que da una distribución equilibrada: 50-50-50.\n",
        "\n",
        "Por otro lado, los clusters generados por el modelo K-Means (usando el número recomendado de clusters k=3) no coinciden exactamente con esta distribución, pero sí con la cantidad de los clusters-especies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7. ¡Obviamente solo hay tres especies, porque ese es el archivo de datos reales!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### ¿Funcionó el clustering con la forma del pétalo?\n",
        "\n",
        "**Respuesta:** Sí. ¿Por qué?:\n",
        "\n",
        "- K-Means es un algoritmo **no supervisado**, lo que significa que **no tiene acceso a las etiquetas reales de las especies (`setosa`, `versicolor`, `virginica`)**.\n",
        "- En lugar de agrupar según las especies, K-Means agrupa los datos en función de las distancias en el espacio de las características (`petal_length` y `petal_width` en este caso), dado esto se puede observar en el paso anterior que los clusters tuvieron una presición elevada para identificar especies con un máximo de error del 8.5% y un mínimo del 4% obtenido por la tabla cruzada:\n",
        "\n",
        "\n",
        "  | Cluster  | setosa | versicolor | virginica |\n",
        "  |----------|--------|------------|-----------|\n",
        "  | 0        | 48     | 0          | 0         |\n",
        "  | 1        | 0      | 4          | 43        |\n",
        "  | 2        | 2      | 46         | 4         |\n",
        "\n",
        "  - **Cluster 0**:\n",
        "    - Tiene 48 observaciones de `setosa`.\n",
        "    - Esto indica que el modelo K-Means identificó correctamente la mayoría de las flores de esta especie como pertenecientes a un único cluster.\n",
        "    - Pero 2 observaciones de `setosa` fueron asignadas incorrectamente a otro cluster (Cluster 2).\n",
        "\n",
        "  - **Cluster 1**:\n",
        "    - Tiene 43 observaciones de `virginica` y 4 observaciones de `versicolor`.\n",
        "    - Este cluster está mayormente compuesto por `virginica`, pero también incluye unas pocas observaciones de `versicolor`.\n",
        "\n",
        "  - **Cluster 2**:\n",
        "    - Tiene 46 observaciones de `versicolor`, 4 observaciones de `virginica`, y 2 observaciones de `setosa`.\n",
        "    - Este cluster está mayormente compuesto por `versicolor`, pero incluye algunas observaciones incorrectas de otras especies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sección 3\n",
        "\n",
        "Utilicen la librería \"kneed\" y vean si el resultado coincide con el método del \"codo\" que hicieron manualmente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Función para determinar el número óptimo de clusters (k) en un DataFrame utilizando la librería `Knee`.\n",
        "\n",
        "Parámetros:\n",
        "- i (int): Valor inicial del rango de clusters a evaluar.\n",
        "- f (int): Valor final del rango de clusters a evaluar.\n",
        "- wcss (list): Lista de valores de WCSS (Within-Cluster Sum of Squares), que representan la dispersión dentro de los clusters.\n",
        "\n",
        "Retorno:\n",
        "- (int): Número óptimo de clusters determinado por el método del codo.\n",
        "\"\"\"\n",
        "\n",
        "def metodoCodoKnee(i, f, wcss):\n",
        "  localizador_codo = KneeLocator(range(i, f+1),\n",
        "                                wcss,\n",
        "                                curve = \"convex\",\n",
        "                                direction = \"decreasing\"\n",
        "                                )\n",
        "  return localizador_codo.elbow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Sépalos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definir el rango de k (de 1 a 10)\n",
        "k_range = range(1, 11)\n",
        "wcss_sep = []  # Lista para almacenar los valores de WCSS\n",
        "\n",
        "# Aplicar K-Means para cada k y calcular WCSS\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    kmeans.fit(iris_df_s1[['sepal_length', 'sepal_width']])\n",
        "    wcss_sep.append(kmeans.inertia_)\n",
        "\n",
        "# Usar KneeLocator para encontrar el punto de codo\n",
        "k_sepalos = KneeLocator(k_range, wcss_sep, curve=\"convex\", direction=\"decreasing\").elbow\n",
        "print(f\"El número recomendado de clústers para sépalos es {k_sepalos}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pétalos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "k_petalos = metodoCodoKnee(i=1, f=10, wcss=wcss_pet)\n",
        "print(f\"El número recomendado de clústers para es {k_petalos}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En el contexto de la cantidad de clusters:\n",
        "\n",
        "- **¿A que podría deberse la diferencia, si la hay?**\n",
        "  - **Respuesta Sépalo:** No hubo diferencia en la cantidad óptima de clusters (k=3). Sin embargo, el clustering basado en los sépalos podría ser menos preciso debido a que las dimensiones del sépalo no separan tan bien a las especies como lo hacen las del pétalo.\n",
        "  - **Respuesta Pétalo:** Principalmente se puede adjudicar a la influencia del escalamiento. Al estandarizar los datos, la forma en que se calculan las distancias cambia, ya que originalmente el ancho del pétalo tenía un rango de 0 a 2.5 cm, mientras que la longitud del pétalo variaba entre 0 y 7 cm. Esta diferencia en escalas pudo haber afectado la asignación de un pequeño número de observaciones, ya que antes del escalamiento, la longitud tenía un mayor peso en la agrupación.\n",
        "- **¿Les dió el número correcto de clusters, comparado a los datos reales?**\n",
        "  - **Respuesta Sépalo:** Sí, el método del codo indicó que 3 clusters era el número óptimo. Sin embargo, el clustering basado solo en sépalos no fue tan preciso, ya que las especies Versicolor y Virginica tienen una superposición en esta dimensión.\n",
        "  - **Respuesta Pétalo:** Sí, el método del codo indicó que 3 clusters era el número óptimo, lo cual coincide con las tres especies reales (setosa, versicolor y virginica).\n",
        "- **Basado en los resultado que tuvieron, ¿A qué conclusiones llegaron?**\n",
        "  \n",
        "  El análisis con K-Means, basado en las dimensiones del pétalo, permitió identificar grupos similares a las especies reales. Sin embargo, presentó algunas imprecisiones en la distribución de las observaciones, ya que es un modelo de agrupación **no supervisado** y no utiliza etiquetas reales para la clasificación. A pesar de esto, el modelo logró una precisión superior al **90%** al relacionar los tres clusters con las especies reales, utilizando únicamente las mediciones de **`petal_length`** y **`petal_width`** del dataset **Iris**.\n",
        "\n",
        "  El clustering con sépalos fue menos preciso, ya que Versicolor y Virginica se superponen en esta dimensión, lo que generó una segmentación menos clara.\n",
        "\n",
        "**Conclusión:** La forma del pétalo es una mejor variable para la segmentación de especies en el dataset Iris, ya que permite una separación más clara entre grupos."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
